defaults:
  - model: mat # mat, mat_baseline
  - map: three_rooms # simple, four_rooms, four_rectangle, three_rooms
  - opt: rmsprop
  - job_logging: disabled

name: 'mat_exp'
gpu: 0
# ==================================================
# configure environment

world: 'default' # default
environment: 'default' # default, shared_mean_reward, shared_max_reward
seed: 921
num_objects: 25
# ==================================================
# configure agent

agent_type: 'mat' # default, mat
brain: 'mat' # default, mat, mat_baseline
view_method: 'local_view' # local_view, relative_view, local_transition_view, local_simple_view
observation_area_mask: 'default'
observation_noise: False # False, sensing_dist, threshold_sensing_dist, flat, flip
noise_threshold_ratio: 0
flip_noise_probabilities: [0.3, 0.2, 0.1]
std_distribution: [0.07, 0.05, 0.03]
past_step: 1
num_agents: 6
init_xys: [[0, 5], [0, 2], [-5, 0], [-2, 0], [0, -2], [0, -5]]
visible_range: 9 # currently only 5, 7, 9 are suppoeted
phase: 'training' # training, evaluation
# ==================================================
# configure training

trainer: 'mat' # default, mat
evaluator: 'default' # default
max_epochs: 10000
max_episode_length: 200
batch_size: 32
populate_steps: 1000
capacity: 100000
gamma: 0.9
epsilon_decay: 0.998
epsilon_initial: 1.0
epsilon_end: 0.05
# ==================================================
# configre validate

validate_epochs: 1000
pretrained_weight_path: False
